{
  "id": "text-generation-webui",
  "name": "Text Generation WebUI",
  "description": "Gradio web UI for running Large Language Models like LLaMA, GPT-J, and more locally",
  "category": "AI",
  "icon": "https://cdn.simpleicons.org/python/3776AB",
  "tags": [
    "llm",
    "ai",
    "text-generation",
    "local",
    "llama",
    "gpt"
  ],
  "min_memory": 8192,
  "min_cpu": 4,
  "min_disk": 20,
  "docker_compose": {
    "version": "3.8",
    "services": {
      "text-generation-webui": {
        "image": "ghcr.io/oobabooga/text-generation-webui:main",
        "container_name": "text-generation-webui",
        "restart": "unless-stopped",
        "volumes": [
          "textgen_models:/app/models",
          "textgen_characters:/app/characters",
          "textgen_loras:/app/loras",
          "textgen_presets:/app/presets",
          "textgen_training:/app/training"
        ],
        "environment": {
          "CLI_ARGS": "--listen --api"
        },
        "network_mode": "host"
      }
    },
    "volumes": {
      "textgen_models": {},
      "textgen_characters": {},
      "textgen_loras": {},
      "textgen_presets": {},
      "textgen_training": {}
    }
  },
  "version": "latest"
}